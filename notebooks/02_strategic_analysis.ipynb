{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 02 - Strategic Analysis\n",
        "\n",
        "Deep strategic analysis of AI agent cost-performance data.\n",
        "\n",
        "**Course:** DATA 230 (Data Visualization) at SJSU\n",
        "\n",
        "## Analysis Sections:\n",
        "1. **Cost-Performance Optimization**: Pareto-optimal configurations, trade-off curves, sweet spots\n",
        "2. **Agent Portfolio Strategy**: Clustering, diversification metrics, capability gaps\n",
        "3. **Risk Assessment**: Failure correlations, systemic risks, Value at Risk (VaR)\n",
        "4. **Business Impact Modeling**: ROI, business value, optimization opportunities\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'plotly'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexpress\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpx\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph_objects\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgo\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KMeans\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'plotly'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load strategic features data\n",
        "df = pd.read_csv('../data/ml/strategic_agent_features.csv')\n",
        "print(f\"Loaded {len(df)} records with {len(df.columns)} features\")\n",
        "print(f\"Columns: {list(df.columns)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Cost-Performance Optimization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Identify Pareto-optimal agent configurations\n",
        "# An agent is Pareto-optimal if no other agent has both lower cost AND higher performance\n",
        "\n",
        "def find_pareto_optimal(df, cost_col='cost_per_task_cents', perf_col='performance_index'):\n",
        "    \"\"\"Find Pareto-optimal points (minimize cost, maximize performance)\"\"\"\n",
        "    pareto_mask = np.ones(len(df), dtype=bool)\n",
        "    \n",
        "    for i in range(len(df)):\n",
        "        for j in range(len(df)):\n",
        "            if i != j:\n",
        "                # j dominates i if j has lower/equal cost AND higher/equal performance (with at least one strict)\n",
        "                if (df[cost_col].iloc[j] <= df[cost_col].iloc[i] and \n",
        "                    df[perf_col].iloc[j] >= df[perf_col].iloc[i] and\n",
        "                    (df[cost_col].iloc[j] < df[cost_col].iloc[i] or \n",
        "                     df[perf_col].iloc[j] > df[perf_col].iloc[i])):\n",
        "                    pareto_mask[i] = False\n",
        "                    break\n",
        "    return pareto_mask\n",
        "\n",
        "# Sample for efficiency (Pareto calculation is O(n²))\n",
        "sample_df = df.sample(n=min(500, len(df)), random_state=42).reset_index(drop=True)\n",
        "sample_df['is_pareto_optimal'] = find_pareto_optimal(sample_df)\n",
        "\n",
        "pareto_count = sample_df['is_pareto_optimal'].sum()\n",
        "print(f\"Pareto-optimal configurations: {pareto_count} out of {len(sample_df)} sampled\")\n",
        "\n",
        "# Show Pareto-optimal agents\n",
        "pareto_agents = sample_df[sample_df['is_pareto_optimal']][['agent_id', 'agent_type', 'model_architecture', 'cost_per_task_cents', 'performance_index']]\n",
        "print(f\"\\nTop Pareto-optimal agents:\")\n",
        "print(pareto_agents.head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate trade-off curves between cost vs performance\n",
        "# Group by cost buckets and calculate average performance\n",
        "\n",
        "df['cost_bucket'] = pd.qcut(df['cost_per_task_cents'], q=10, labels=False, duplicates='drop')\n",
        "tradeoff_curve = df.groupby('cost_bucket').agg({\n",
        "    'cost_per_task_cents': 'mean',\n",
        "    'performance_index': 'mean',\n",
        "    'success_rate': 'mean',\n",
        "    'agent_id': 'count'\n",
        "}).rename(columns={'agent_id': 'count'}).reset_index()\n",
        "\n",
        "print(\"Cost-Performance Trade-off Curve:\")\n",
        "print(tradeoff_curve)\n",
        "\n",
        "# Calculate marginal performance gain per cost increase\n",
        "tradeoff_curve['marginal_perf_gain'] = tradeoff_curve['performance_index'].diff() / tradeoff_curve['cost_per_task_cents'].diff()\n",
        "print(\"\\nMarginal Performance Gain per Cost Unit:\")\n",
        "print(tradeoff_curve[['cost_bucket', 'cost_per_task_cents', 'performance_index', 'marginal_perf_gain']])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find \"sweet spot\" configurations for each task category\n",
        "# Sweet spot = best cost_efficiency_ratio within each task_category\n",
        "\n",
        "sweet_spots = df.loc[df.groupby('task_category')['cost_efficiency_ratio'].idxmax()]\n",
        "sweet_spots_summary = sweet_spots[['task_category', 'agent_type', 'model_architecture', \n",
        "                                    'cost_per_task_cents', 'performance_index', 'cost_efficiency_ratio']]\n",
        "\n",
        "print(\"Sweet Spot Configurations by Task Category:\")\n",
        "print(sweet_spots_summary.sort_values('cost_efficiency_ratio', ascending=False))\n",
        "\n",
        "# Calculate average metrics for sweet spots vs overall\n",
        "print(f\"\\nSweet Spot Average Performance: {sweet_spots['performance_index'].mean():.4f}\")\n",
        "print(f\"Overall Average Performance: {df['performance_index'].mean():.4f}\")\n",
        "print(f\"Sweet Spot Average Cost: {sweet_spots['cost_per_task_cents'].mean():.4f}\")\n",
        "print(f\"Overall Average Cost: {df['cost_per_task_cents'].mean():.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Agent Portfolio Strategy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cluster agents into strategic categories: Workhorses, Specialists, Underperformers\n",
        "# Using performance_index, cost_efficiency_ratio, and success_rate\n",
        "\n",
        "clustering_features = ['performance_index', 'cost_efficiency_ratio', 'success_rate', 'efficiency_score']\n",
        "X_cluster = df[clustering_features].copy()\n",
        "X_cluster = X_cluster.fillna(X_cluster.mean())\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_cluster)\n",
        "\n",
        "# K-means with 3 clusters\n",
        "kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
        "df['cluster'] = kmeans.fit_predict(X_scaled)\n",
        "\n",
        "# Analyze clusters to label them\n",
        "cluster_stats = df.groupby('cluster')[clustering_features].mean()\n",
        "print(\"Cluster Statistics:\")\n",
        "print(cluster_stats)\n",
        "\n",
        "# Label clusters based on characteristics\n",
        "cluster_labels = {}\n",
        "for cluster_id in range(3):\n",
        "    perf = cluster_stats.loc[cluster_id, 'performance_index']\n",
        "    cost_eff = cluster_stats.loc[cluster_id, 'cost_efficiency_ratio']\n",
        "    \n",
        "    if perf > cluster_stats['performance_index'].median() and cost_eff > cluster_stats['cost_efficiency_ratio'].median():\n",
        "        cluster_labels[cluster_id] = 'Workhorse'\n",
        "    elif perf > cluster_stats['performance_index'].median():\n",
        "        cluster_labels[cluster_id] = 'Specialist'\n",
        "    else:\n",
        "        cluster_labels[cluster_id] = 'Underperformer'\n",
        "\n",
        "df['strategic_category'] = df['cluster'].map(cluster_labels)\n",
        "print(\"\\nStrategic Category Distribution:\")\n",
        "print(df['strategic_category'].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate portfolio diversification metrics\n",
        "# Herfindahl-Hirschman Index (HHI) for concentration\n",
        "\n",
        "# By agent_type\n",
        "agent_type_shares = df['agent_type'].value_counts(normalize=True)\n",
        "hhi_agent_type = (agent_type_shares ** 2).sum()\n",
        "\n",
        "# By model_architecture\n",
        "arch_shares = df['model_architecture'].value_counts(normalize=True)\n",
        "hhi_architecture = (arch_shares ** 2).sum()\n",
        "\n",
        "# By strategic_category\n",
        "category_shares = df['strategic_category'].value_counts(normalize=True)\n",
        "hhi_category = (category_shares ** 2).sum()\n",
        "\n",
        "print(\"Portfolio Diversification Metrics (HHI):\")\n",
        "print(f\"Agent Type HHI: {hhi_agent_type:.4f} (lower = more diversified)\")\n",
        "print(f\"Architecture HHI: {hhi_architecture:.4f}\")\n",
        "print(f\"Strategic Category HHI: {hhi_category:.4f}\")\n",
        "\n",
        "# Diversification score (inverse of average HHI)\n",
        "diversification_score = 1 - (hhi_agent_type + hhi_architecture + hhi_category) / 3\n",
        "print(f\"\\nOverall Diversification Score: {diversification_score:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Identify gaps in agent capability coverage\n",
        "# Check which task_category + deployment_environment combinations have low coverage or poor performance\n",
        "\n",
        "coverage_matrix = df.groupby(['task_category', 'deployment_environment']).agg({\n",
        "    'agent_id': 'count',\n",
        "    'performance_index': 'mean',\n",
        "    'success_rate': 'mean'\n",
        "}).rename(columns={'agent_id': 'agent_count'}).reset_index()\n",
        "\n",
        "# Identify gaps (low agent count or low performance)\n",
        "coverage_matrix['is_gap'] = (\n",
        "    (coverage_matrix['agent_count'] < coverage_matrix['agent_count'].quantile(0.25)) |\n",
        "    (coverage_matrix['performance_index'] < coverage_matrix['performance_index'].quantile(0.25))\n",
        ")\n",
        "\n",
        "print(\"Capability Coverage Gaps:\")\n",
        "gaps = coverage_matrix[coverage_matrix['is_gap']]\n",
        "print(gaps.sort_values('performance_index'))\n",
        "\n",
        "print(f\"\\nTotal gaps identified: {len(gaps)} out of {len(coverage_matrix)} combinations\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Risk Assessment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build failure correlation matrices\n",
        "# Calculate failure rate (1 - success_rate) correlations across different dimensions\n",
        "\n",
        "df['failure_rate'] = 1 - df['success_rate']\n",
        "\n",
        "# Correlation matrix for risk-related metrics\n",
        "risk_metrics = ['failure_rate', 'operational_risk_index', 'degradation_risk_score', \n",
        "                'task_complexity', 'execution_time_seconds', 'response_latency_ms']\n",
        "risk_correlation = df[risk_metrics].corr()\n",
        "\n",
        "print(\"Failure Correlation Matrix:\")\n",
        "print(risk_correlation.round(3))\n",
        "\n",
        "# Identify highly correlated risk factors (potential systemic risks)\n",
        "high_corr_pairs = []\n",
        "for i in range(len(risk_metrics)):\n",
        "    for j in range(i+1, len(risk_metrics)):\n",
        "        corr = risk_correlation.iloc[i, j]\n",
        "        if abs(corr) > 0.5:\n",
        "            high_corr_pairs.append((risk_metrics[i], risk_metrics[j], corr))\n",
        "\n",
        "print(\"\\nHighly Correlated Risk Factors (|corr| > 0.5):\")\n",
        "for pair in high_corr_pairs:\n",
        "    print(f\"  {pair[0]} <-> {pair[1]}: {pair[2]:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Identify systemic risk factors\n",
        "# Factors that affect multiple agent types or architectures similarly\n",
        "\n",
        "# Calculate failure rate variance explained by different groupings\n",
        "systemic_risks = {}\n",
        "\n",
        "# By model_architecture\n",
        "arch_failure = df.groupby('model_architecture')['failure_rate'].agg(['mean', 'std', 'count'])\n",
        "systemic_risks['model_architecture'] = arch_failure['mean'].std()\n",
        "\n",
        "# By deployment_environment\n",
        "env_failure = df.groupby('deployment_environment')['failure_rate'].agg(['mean', 'std', 'count'])\n",
        "systemic_risks['deployment_environment'] = env_failure['mean'].std()\n",
        "\n",
        "# By task_category\n",
        "task_failure = df.groupby('task_category')['failure_rate'].agg(['mean', 'std', 'count'])\n",
        "systemic_risks['task_category'] = task_failure['mean'].std()\n",
        "\n",
        "print(\"Systemic Risk Factors (variance in failure rate across groups):\")\n",
        "for factor, risk in sorted(systemic_risks.items(), key=lambda x: x[1], reverse=True):\n",
        "    print(f\"  {factor}: {risk:.4f}\")\n",
        "\n",
        "print(\"\\nHighest Risk Architecture:\")\n",
        "print(arch_failure.sort_values('mean', ascending=False).head(3))\n",
        "\n",
        "print(\"\\nHighest Risk Environment:\")\n",
        "print(env_failure.sort_values('mean', ascending=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate Value at Risk (VaR) for agent deployments\n",
        "# VaR = potential loss at a given confidence level\n",
        "\n",
        "# Cost-based VaR (95% confidence)\n",
        "confidence_level = 0.95\n",
        "\n",
        "# Total cost distribution\n",
        "df['potential_loss'] = df['cost_per_task_cents'] * df['failure_rate']\n",
        "var_95 = df['potential_loss'].quantile(confidence_level)\n",
        "cvar_95 = df[df['potential_loss'] >= var_95]['potential_loss'].mean()  # Conditional VaR\n",
        "\n",
        "print(f\"Value at Risk Analysis (95% confidence):\")\n",
        "print(f\"  VaR (95%): {var_95:.4f} cents per task\")\n",
        "print(f\"  CVaR (Expected Shortfall): {cvar_95:.4f} cents per task\")\n",
        "\n",
        "# VaR by agent_type\n",
        "var_by_type = df.groupby('agent_type')['potential_loss'].quantile(confidence_level)\n",
        "print(f\"\\nVaR by Agent Type (95%):\")\n",
        "print(var_by_type.sort_values(ascending=False).head(10))\n",
        "\n",
        "# Identify high-risk agents (top 5% potential loss)\n",
        "high_risk_threshold = df['potential_loss'].quantile(0.95)\n",
        "high_risk_agents = df[df['potential_loss'] >= high_risk_threshold]\n",
        "print(f\"\\nHigh-Risk Agents (top 5%): {len(high_risk_agents)} agents\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Business Impact Modeling\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate ROI for each agent type\n",
        "# ROI = (Value Generated - Cost) / Cost\n",
        "# Proxy value generated = success_rate * performance_index (normalized)\n",
        "\n",
        "df['value_generated'] = df['success_rate'] * df['performance_index']\n",
        "df['roi'] = (df['value_generated'] - df['cost_per_task_cents']) / df['cost_per_task_cents']\n",
        "\n",
        "# ROI by agent_type\n",
        "roi_by_type = df.groupby('agent_type').agg({\n",
        "    'roi': 'mean',\n",
        "    'value_generated': 'mean',\n",
        "    'cost_per_task_cents': 'mean',\n",
        "    'agent_id': 'count'\n",
        "}).rename(columns={'agent_id': 'count'}).sort_values('roi', ascending=False)\n",
        "\n",
        "print(\"ROI by Agent Type:\")\n",
        "print(roi_by_type.head(15))\n",
        "\n",
        "# ROI by model_architecture\n",
        "roi_by_arch = df.groupby('model_architecture').agg({\n",
        "    'roi': 'mean',\n",
        "    'value_generated': 'mean',\n",
        "    'cost_per_task_cents': 'mean'\n",
        "}).sort_values('roi', ascending=False)\n",
        "\n",
        "print(\"\\nROI by Model Architecture:\")\n",
        "print(roi_by_arch)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Estimate business value created per agent\n",
        "# Business value = performance * efficiency * (1 - risk)\n",
        "\n",
        "df['business_value'] = (\n",
        "    df['performance_index'] * \n",
        "    df['efficiency_score'] * \n",
        "    (1 - df['operational_risk_index'].clip(upper=1))\n",
        ")\n",
        "\n",
        "# Aggregate by agent_type\n",
        "business_value_by_type = df.groupby('agent_type').agg({\n",
        "    'business_value': ['mean', 'sum', 'std'],\n",
        "    'agent_id': 'count'\n",
        "})\n",
        "business_value_by_type.columns = ['avg_value', 'total_value', 'value_std', 'count']\n",
        "business_value_by_type = business_value_by_type.sort_values('total_value', ascending=False)\n",
        "\n",
        "print(\"Business Value by Agent Type:\")\n",
        "print(business_value_by_type.head(15))\n",
        "\n",
        "# Total business value\n",
        "total_value = df['business_value'].sum()\n",
        "print(f\"\\nTotal Business Value Generated: {total_value:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Identify high-leverage optimization opportunities\n",
        "# Agents with high potential but currently underperforming\n",
        "\n",
        "df['optimization_potential'] = (\n",
        "    df['scalability_potential'] * \n",
        "    (1 - df['success_rate']) *  # Room for improvement\n",
        "    df['cost_efficiency_ratio']  # Cost-effective to optimize\n",
        ")\n",
        "\n",
        "# Top optimization opportunities\n",
        "optimization_opportunities = df.nlargest(20, 'optimization_potential')[\n",
        "    ['agent_id', 'agent_type', 'model_architecture', 'success_rate', \n",
        "     'scalability_potential', 'optimization_potential']\n",
        "]\n",
        "\n",
        "print(\"Top 20 High-Leverage Optimization Opportunities:\")\n",
        "print(optimization_opportunities)\n",
        "\n",
        "# Aggregate by agent_type\n",
        "optimization_by_type = df.groupby('agent_type')['optimization_potential'].agg(['mean', 'sum']).sort_values('sum', ascending=False)\n",
        "print(\"\\nOptimization Potential by Agent Type:\")\n",
        "print(optimization_by_type.head(10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Strategic Insights Report\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate Strategic Insights Report\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"STRATEGIC INSIGHTS REPORT: AI Agent Performance Intelligence System\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(\"\\n### 1. COST-PERFORMANCE OPTIMIZATION\")\n",
        "print(\"-\" * 40)\n",
        "print(f\"• Pareto-optimal configurations identified: {pareto_count} agents\")\n",
        "print(f\"• Sweet spot configurations found for {len(sweet_spots)} task categories\")\n",
        "print(f\"• Best marginal performance gain at cost bucket: {tradeoff_curve.loc[tradeoff_curve['marginal_perf_gain'].idxmax(), 'cost_bucket'] if tradeoff_curve['marginal_perf_gain'].notna().any() else 'N/A'}\")\n",
        "\n",
        "print(\"\\n### 2. AGENT PORTFOLIO STRATEGY\")\n",
        "print(\"-\" * 40)\n",
        "category_counts = df['strategic_category'].value_counts()\n",
        "for cat, count in category_counts.items():\n",
        "    print(f\"• {cat}: {count} agents ({count/len(df)*100:.1f}%)\")\n",
        "print(f\"• Portfolio Diversification Score: {diversification_score:.2f}\")\n",
        "print(f\"• Capability gaps identified: {len(gaps)} areas\")\n",
        "\n",
        "print(\"\\n### 3. RISK ASSESSMENT\")\n",
        "print(\"-\" * 40)\n",
        "print(f\"• Value at Risk (95%): {var_95:.4f} cents/task\")\n",
        "print(f\"• Conditional VaR: {cvar_95:.4f} cents/task\")\n",
        "print(f\"• High-risk agents: {len(high_risk_agents)} ({len(high_risk_agents)/len(df)*100:.1f}%)\")\n",
        "highest_risk_factor = max(systemic_risks, key=systemic_risks.get)\n",
        "print(f\"• Highest systemic risk factor: {highest_risk_factor}\")\n",
        "\n",
        "print(\"\\n### 4. BUSINESS IMPACT\")\n",
        "print(\"-\" * 40)\n",
        "print(f\"• Total business value generated: {total_value:.2f}\")\n",
        "print(f\"• Average ROI: {df['roi'].mean():.2f}\")\n",
        "top_roi_type = roi_by_type.index[0]\n",
        "print(f\"• Highest ROI agent type: {top_roi_type} ({roi_by_type.loc[top_roi_type, 'roi']:.2f})\")\n",
        "\n",
        "print(\"\\n### 5. ACTIONABLE RECOMMENDATIONS\")\n",
        "print(\"-\" * 40)\n",
        "print(\"1. OPTIMIZE: Focus on high-leverage optimization opportunities identified\")\n",
        "print(\"2. RETIRE: Consider retiring Underperformer agents with low ROI\")\n",
        "print(\"3. SCALE: Expand Workhorse agents in high-demand task categories\")\n",
        "print(\"4. DIVERSIFY: Address capability gaps in underserved task-environment combinations\")\n",
        "print(\"5. MITIGATE: Implement risk controls for high-VaR agent deployments\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save analysis results\n",
        "analysis_columns = [\n",
        "    'agent_id', 'agent_type', 'model_architecture', 'deployment_environment', 'task_category',\n",
        "    'performance_index', 'success_rate', 'cost_per_task_cents', 'cost_efficiency_ratio',\n",
        "    'strategic_category', 'failure_rate', 'potential_loss', 'roi', 'business_value', 'optimization_potential'\n",
        "]\n",
        "\n",
        "df[analysis_columns].to_csv('../data/ml/strategic_analysis_results.csv', index=False)\n",
        "print(\"Analysis results saved to data/ml/strategic_analysis_results.csv\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
