{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 01 - Advanced Feature Engineering\n",
        "\n",
        "This notebook implements sophisticated feature engineering for AI agent performance analysis.\n",
        "\n",
        "**Course:** DATA 230 (Data Visualization) at SJSU\n",
        "\n",
        "## Features Created:\n",
        "1. **Business-Centric Features**: business_value_score, operational_risk_index, scalability_potential, total_cost_of_ownership\n",
        "2. **Temporal Intelligence**: performance_trend_7d, stability_index, degradation_risk_score, seasonality_impact\n",
        "3. **Strategic Groupings**: performance_quartile, cost_efficiency_tier, strategic_importance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 5000 records\n",
            "Columns: ['agent_id', 'agent_type', 'model_architecture', 'deployment_environment', 'task_category', 'task_complexity', 'autonomy_level', 'success_rate', 'accuracy_score', 'efficiency_score', 'execution_time_seconds', 'response_latency_ms', 'memory_usage_mb', 'cpu_usage_percent', 'cost_per_task_cents', 'human_intervention_required', 'error_recovery_rate', 'multimodal_capability', 'edge_compatibility', 'privacy_compliance_score', 'bias_detection_score', 'timestamp', 'data_quality_score', 'performance_index', 'cost_efficiency_ratio', 'autonomous_capability_score']\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load cleaned data\n",
        "df = pd.read_csv('../data/cleaned/cleaned_data.csv')\n",
        "print(f\"Loaded {len(df)} records\")\n",
        "print(f\"Columns: {list(df.columns)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Business-Centric Features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "business_value_score created\n",
            "count    5000.000000\n",
            "mean        0.334121\n",
            "std         0.137408\n",
            "min         0.190440\n",
            "25%         0.234735\n",
            "50%         0.295188\n",
            "75%         0.365727\n",
            "max         0.862132\n",
            "Name: business_value_score, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Convert human_intervention_required to numeric (frequency proxy)\n",
        "df['human_intervention_frequency'] = df['human_intervention_required'].astype(int)\n",
        "\n",
        "# Calculate cost_efficiency and resource_efficiency for use in business_value_score\n",
        "df['cost_efficiency'] = df['cost_efficiency_ratio'] / df['cost_efficiency_ratio'].max()\n",
        "df['resource_efficiency'] = df['efficiency_score'] / (df['memory_usage_mb'] * df['cpu_usage_percent']) * 1000\n",
        "df['resource_efficiency'] = df['resource_efficiency'] / df['resource_efficiency'].max()\n",
        "\n",
        "# business_value_score: Weighted combination\n",
        "df['business_value_score'] = (\n",
        "    df['success_rate'] * 0.25 +\n",
        "    df['cost_efficiency'] * 0.20 +\n",
        "    df['resource_efficiency'] * 0.15 +\n",
        "    (1 - df['human_intervention_frequency']) * 0.20 +\n",
        "    df['error_recovery_rate'] * 0.10 +\n",
        "    df['privacy_compliance_score'] * 0.10\n",
        ")\n",
        "\n",
        "print(\"business_value_score created\")\n",
        "print(df['business_value_score'].describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "operational_risk_index created\n",
            "count    5000.000000\n",
            "mean        0.792723\n",
            "std         0.313032\n",
            "min         0.033500\n",
            "25%         0.566540\n",
            "50%         0.821600\n",
            "75%         1.044957\n",
            "max         1.472300\n",
            "Name: operational_risk_index, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# operational_risk_index: Combination of failure_probability + maintenance_complexity + dependency_score\n",
        "df['failure_probability'] = 1 - df['success_rate']\n",
        "df['maintenance_complexity'] = df['task_complexity'] / 10 * (1 - df['error_recovery_rate'])\n",
        "df['dependency_score'] = (1 - df['autonomous_capability_score'] / 100) * df['human_intervention_frequency']\n",
        "\n",
        "df['operational_risk_index'] = (\n",
        "    df['failure_probability'] +\n",
        "    df['maintenance_complexity'] +\n",
        "    df['dependency_score']\n",
        ")\n",
        "\n",
        "print(\"operational_risk_index created\")\n",
        "print(df['operational_risk_index'].describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "scalability_potential created\n",
            "count    5000.000000\n",
            "mean        0.019100\n",
            "std         0.039798\n",
            "min        -0.000810\n",
            "25%         0.000811\n",
            "50%         0.004653\n",
            "75%         0.018307\n",
            "max         0.526337\n",
            "Name: scalability_potential, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# scalability_potential: Based on performance trends and resource efficiency\n",
        "df['scalability_potential'] = (\n",
        "    df['performance_index'] * df['resource_efficiency'] * \n",
        "    (1 - df['cpu_usage_percent'] / 100) * \n",
        "    (1 - df['memory_usage_mb'] / df['memory_usage_mb'].max())\n",
        ")\n",
        "\n",
        "print(\"scalability_potential created\")\n",
        "print(df['scalability_potential'].describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total_cost_of_ownership created\n",
            "count    5000.000000\n",
            "mean        5.196098\n",
            "std         5.793033\n",
            "min         0.000366\n",
            "25%         1.352660\n",
            "50%         3.369967\n",
            "75%         6.964168\n",
            "max        48.126353\n",
            "Name: total_cost_of_ownership, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# total_cost_of_ownership: (cost_per_task * execution_frequency) + (maintenance_cost * complexity)\n",
        "# Proxy execution_frequency from execution_time (higher time = lower frequency possible)\n",
        "df['execution_frequency_proxy'] = 1 / df['execution_time_seconds']\n",
        "df['maintenance_cost_proxy'] = df['human_intervention_frequency'] * df['response_latency_ms'] / 1000\n",
        "\n",
        "df['total_cost_of_ownership'] = (\n",
        "    df['cost_per_task_cents'] * df['execution_frequency_proxy'] +\n",
        "    df['maintenance_cost_proxy'] * df['task_complexity']\n",
        ")\n",
        "\n",
        "print(\"total_cost_of_ownership created\")\n",
        "print(df['total_cost_of_ownership'].describe())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Temporal Intelligence\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "performance_trend_7d created\n",
            "count    5000.000000\n",
            "mean        0.000010\n",
            "std         0.028892\n",
            "min        -0.227180\n",
            "25%        -0.018932\n",
            "50%         0.000124\n",
            "75%         0.018510\n",
            "max         0.300470\n",
            "Name: performance_trend_7d, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Parse timestamp\n",
        "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "df['hour_of_day'] = df['timestamp'].dt.hour\n",
        "df['day_of_week'] = df['timestamp'].dt.dayofweek\n",
        "\n",
        "# performance_trend_7d: Slope of performance metrics over time (rolling window proxy)\n",
        "# Group by agent_type and calculate rolling mean difference as trend proxy\n",
        "df = df.sort_values(['agent_type', 'timestamp'])\n",
        "df['performance_trend_7d'] = df.groupby('agent_type')['performance_index'].transform(\n",
        "    lambda x: x.diff().rolling(window=7, min_periods=1).mean()\n",
        ")\n",
        "df['performance_trend_7d'] = df['performance_trend_7d'].fillna(0)\n",
        "\n",
        "print(\"performance_trend_7d created\")\n",
        "print(df['performance_trend_7d'].describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "stability_index created\n",
            "count    5000.000000\n",
            "mean        0.676363\n",
            "std         0.009080\n",
            "min         0.658132\n",
            "25%         0.670768\n",
            "50%         0.677628\n",
            "75%         0.682751\n",
            "max         0.690483\n",
            "Name: stability_index, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# stability_index: 1 - (coefficient of variation of success_rate)\n",
        "# Calculate CV per agent_type\n",
        "cv_by_agent = df.groupby('agent_type')['success_rate'].transform(\n",
        "    lambda x: x.std() / x.mean() if x.mean() != 0 else 0\n",
        ")\n",
        "df['stability_index'] = 1 - cv_by_agent\n",
        "df['stability_index'] = df['stability_index'].clip(lower=0, upper=1)\n",
        "\n",
        "print(\"stability_index created\")\n",
        "print(df['stability_index'].describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "degradation_risk_score created\n",
            "count    5000.000000\n",
            "mean        0.285585\n",
            "std         0.050500\n",
            "min         0.134288\n",
            "25%         0.245746\n",
            "50%         0.290290\n",
            "75%         0.333733\n",
            "max         0.399184\n",
            "Name: degradation_risk_score, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# degradation_risk_score: Probability of performance decline based on historical patterns\n",
        "# Higher risk if: low stability, negative trend, high failure probability\n",
        "df['degradation_risk_score'] = (\n",
        "    (1 - df['stability_index']) * 0.4 +\n",
        "    (-df['performance_trend_7d'].clip(upper=0)) * 0.3 +\n",
        "    df['failure_probability'] * 0.3\n",
        ")\n",
        "df['degradation_risk_score'] = df['degradation_risk_score'].clip(lower=0, upper=1)\n",
        "\n",
        "print(\"degradation_risk_score created\")\n",
        "print(df['degradation_risk_score'].describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "seasonality_impact created\n",
            "count    5000.000000\n",
            "mean        0.005090\n",
            "std         0.003032\n",
            "min         0.001982\n",
            "25%         0.002909\n",
            "50%         0.004306\n",
            "75%         0.006259\n",
            "max         0.011875\n",
            "Name: seasonality_impact, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# seasonality_impact: Performance variation by hour/day patterns\n",
        "# Calculate mean performance by hour and day, then deviation from overall mean\n",
        "hourly_perf = df.groupby('hour_of_day')['performance_index'].transform('mean')\n",
        "daily_perf = df.groupby('day_of_week')['performance_index'].transform('mean')\n",
        "overall_mean = df['performance_index'].mean()\n",
        "\n",
        "df['seasonality_impact'] = (\n",
        "    (hourly_perf - overall_mean).abs() / overall_mean +\n",
        "    (daily_perf - overall_mean).abs() / overall_mean\n",
        ") / 2\n",
        "\n",
        "print(\"seasonality_impact created\")\n",
        "print(df['seasonality_impact'].describe())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Strategic Groupings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "performance_quartile created\n",
            "performance_quartile\n",
            "1    1255\n",
            "2    1248\n",
            "3    1246\n",
            "4    1251\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# performance_quartile: Relative performance within agent_type\n",
        "df['performance_quartile'] = df.groupby('agent_type')['performance_index'].transform(\n",
        "    lambda x: pd.qcut(x, q=4, labels=[1, 2, 3, 4], duplicates='drop')\n",
        ")\n",
        "df['performance_quartile'] = df['performance_quartile'].astype(int)\n",
        "\n",
        "print(\"performance_quartile created\")\n",
        "print(df['performance_quartile'].value_counts().sort_index())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cost_efficiency_tier created\n",
            "cost_efficiency_tier\n",
            "Very Low     1000\n",
            "Low          1000\n",
            "Medium       1000\n",
            "High         1000\n",
            "Very High    1000\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# cost_efficiency_tier: Cost-performance ranking\n",
        "df['cost_efficiency_tier'] = pd.qcut(\n",
        "    df['cost_efficiency_ratio'], \n",
        "    q=5, \n",
        "    labels=['Very Low', 'Low', 'Medium', 'High', 'Very High'],\n",
        "    duplicates='drop'\n",
        ")\n",
        "\n",
        "print(\"cost_efficiency_tier created\")\n",
        "print(df['cost_efficiency_tier'].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "strategic_importance created\n",
            "strategic_importance\n",
            "Low       2584\n",
            "Medium    2409\n",
            "High         7\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# strategic_importance: Business impact classification\n",
        "# Based on business_value_score and task_complexity\n",
        "def classify_importance(row):\n",
        "    if row['business_value_score'] >= 0.7 and row['task_complexity'] >= 7:\n",
        "        return 'Critical'\n",
        "    elif row['business_value_score'] >= 0.5 and row['task_complexity'] >= 5:\n",
        "        return 'High'\n",
        "    elif row['business_value_score'] >= 0.3:\n",
        "        return 'Medium'\n",
        "    else:\n",
        "        return 'Low'\n",
        "\n",
        "df['strategic_importance'] = df.apply(classify_importance, axis=1)\n",
        "\n",
        "print(\"strategic_importance created\")\n",
        "print(df['strategic_importance'].value_counts())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary and Save\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total new features created: 11\n",
            "\n",
            "New features: ['business_value_score', 'operational_risk_index', 'scalability_potential', 'total_cost_of_ownership', 'performance_trend_7d', 'stability_index', 'degradation_risk_score', 'seasonality_impact', 'performance_quartile', 'cost_efficiency_tier', 'strategic_importance']\n",
            "\n",
            "Final dataset shape: (5000, 47)\n"
          ]
        }
      ],
      "source": [
        "# List all new features created\n",
        "new_features = [\n",
        "    # Business-Centric\n",
        "    'business_value_score',\n",
        "    'operational_risk_index',\n",
        "    'scalability_potential',\n",
        "    'total_cost_of_ownership',\n",
        "    # Temporal Intelligence\n",
        "    'performance_trend_7d',\n",
        "    'stability_index',\n",
        "    'degradation_risk_score',\n",
        "    'seasonality_impact',\n",
        "    # Strategic Groupings\n",
        "    'performance_quartile',\n",
        "    'cost_efficiency_tier',\n",
        "    'strategic_importance'\n",
        "]\n",
        "\n",
        "print(f\"Total new features created: {len(new_features)}\")\n",
        "print(f\"\\nNew features: {new_features}\")\n",
        "print(f\"\\nFinal dataset shape: {df.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final dataset shape after cleanup: (5000, 37)\n"
          ]
        }
      ],
      "source": [
        "# Drop intermediate calculation columns\n",
        "columns_to_drop = [\n",
        "    'human_intervention_frequency',\n",
        "    'cost_efficiency',\n",
        "    'resource_efficiency',\n",
        "    'failure_probability',\n",
        "    'maintenance_complexity',\n",
        "    'dependency_score',\n",
        "    'execution_frequency_proxy',\n",
        "    'maintenance_cost_proxy',\n",
        "    'hour_of_day',\n",
        "    'day_of_week'\n",
        "]\n",
        "df.drop(columns=columns_to_drop, inplace=True, errors='ignore')\n",
        "\n",
        "# Handle any infinities\n",
        "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "print(f\"Final dataset shape after cleanup: {df.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved to data/ml/strategic_agent_features.csv\n"
          ]
        }
      ],
      "source": [
        "# Save enhanced dataset\n",
        "df.to_csv('../data/ml/strategic_agent_features.csv', index=False)\n",
        "print(\"Saved to data/ml/strategic_agent_features.csv\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
